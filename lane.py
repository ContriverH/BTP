# -*- coding: utf-8 -*-
"""road_lane_detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1w6xv6v5xuQPmMJMMQ5MZnGlC6F9bsi7Q
"""

# ROAD LANE DETECTION

import cv2
# import matplotlib.pyplot as plt
import numpy as np


# Capturing the original video
# cap = cv2.VideoCapture('Highway.mp4')

# image_path = "road_lane.png"
# image2 = cv2.imread(image_path)
# cap = cv2.VideoCapture('Highway.mp4')

coordinates = []


def grey(image):
  # convert to grayscale
    image = np.asarray(image)
    return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)

# Apply Gaussian Blur --> Reduce noise and smoothen image


def gauss(image):
    return cv2.GaussianBlur(image, (5, 5), 0)

  # outline the strongest gradients in the image --> this is where lines in the image are


def canny(image):
    edges = cv2.Canny(image, 50, 150)
    return edges


def region(image):
    height, width = image.shape
    # isolate the gradients that correspond to the lane lines
    triangle = np.array([
        [(100, height), (475, 325), (width, height)]
    ])
    # create a black image with the same dimensions as original image
    mask = np.zeros_like(image)
    # create a mask (triangle that isolates the region of interest in our image)
    mask = cv2.fillPoly(mask, triangle, 255)
    mask = cv2.bitwise_and(image, mask)
    return mask

# there will be two lines drawn based on 4 coordinates, and the below coordinate is what we are trying to capture in the cor and then append it coordinates as left starting and right starting point.


def display_lines(image, lines):
    cor = []
    lines_image = np.zeros_like(image)
    # make sure array isn't empty
    if lines is not None:
        for line in lines:
            x1, y1, x2, y2 = line
            # print(x1, y1)
            cor.append([x1, y1])
            # draw lines on a black image
            cv2.line(lines_image, (x1, y1), (x2, y2), (255, 0, 0), 10)
    coordinates.append(cor)
    return lines_image
    # it is returning an image with two lines drawn on it on the basis of four coordinates


def make_points(image, average):
    # print(average)
    slope, y_int = average
    y1 = image.shape[0]
    # how long we want our lines to be --> 3/5 the size of the image
    y2 = int(y1 * (3/5))
    # determine algebraically
    x1 = int((y1 - y_int) // slope)
    x2 = int((y2 - y_int) // slope)
    return np.array([x1, y1, x2, y2])
    # getting the coordinates of the lines based on slope and y-intercept and making the coordinates to cover 3/5 th part of the image height


def average(image, lines):
    left = []
    right = []

    if lines is not None:
        for line in lines:
            # print(line)
            x1, y1, x2, y2 = line.reshape(4)
            # fit line to points, return slope and y-int
            parameters = np.polyfit((x1, x2), (y1, y2), 1)
            # print(parameters)
            slope = parameters[0]
            y_int = parameters[1]
            # lines on the right have positive slope, and lines on the left have neg slope
            if slope < 0:
                left.append((slope, y_int))
            else:
                right.append((slope, y_int))

    # takes average among all the columns (column0: slope, column1: y_int)
    right_avg = np.average(right, axis=0)
    left_avg = np.average(left, axis=0)
    # create lines based on averages calculates
    left_line = make_points(image, left_avg)
    right_line = make_points(image, right_avg)
    return np.array([left_line, right_line])
    # calculating the slope and y-intercept of the left and right line based on the average of all the res. left and right line's coordinates
    # then in the end it is returning the coordinates of the lines as [left line coordinates, right line coordinates]


def preprocess(video_path):
    n = 10
    cap = cv2.VideoCapture(video_path)
    while n >= 0:
        # print(10 - n)
        ret, frame = cap.read()
        '''##### DETECTING lane lines in image ######'''

        frame_copy = np.copy(frame)
        # this is for the detecting edges
        edges = cv2.Canny(frame_copy, 50, 150)
        # selecting a triangular shape area for lane detection
        isolated = region(edges)
        # cv2.imshow(edges)
        # cv2.imshow(isolated)

        # to see the image one by one, you can uncomment it
        # cv2.waitKey(0)

        # DRAWING LINES: (order of params) --> region of interest, bin size (P, theta), min intersections needed, placeholder array,
        lines = cv2.HoughLinesP(
            isolated, 2, np.pi/180, 100, np.array([]), minLineLength=40, maxLineGap=5)
        averaged_lines = average(frame_copy, lines)
        black_lines = display_lines(frame_copy, averaged_lines)
        # taking wighted sum of original image and lane lines image
        lanes = cv2.addWeighted(frame_copy, 0.8, black_lines, 1, 1)
        cv2.imshow("lanes", lanes)
        # if cv2.waitKey(1)
        # cv2.destroyAllWindows()
        cv2.waitKey(1)

        n -= 1
    cap.release()  # release video capture object
    # destroying all running videos after the execution end
    cv2.destroyAllWindows()

    # getting the average of all coordinates
    average_coordinates = np.average(
        coordinates, axis=0) + [[30, -30], [-30, -30]]  # padding, so that the mask does not go out of range

    return average_coordinates


print(preprocess('Highway.mp4'))
# print(preprocess('test2.mp4'))
# preprocess(image2)


# the frame size is 1280 * 720
